# Week 13–14: 프로젝트 C — 공개 RTSP 영상 기반 DeepStream + YOLO 성능 비교

## 1. 목표
- **공개 RTSP 서버에서 실시간 영상**을 받아 **Jetson Nano**에서 YOLO 모델을 활용해 객체 탐지 수행  
- **DeepStream 파이프라인**과 **YOLO 단독 실행(OpenCV 기반)**을 각각 실행하여 성능(FPS, Latency, 자원 사용률)을 비교  
- 결과를 Matplotlib 그래프로 시각화하여 DeepStream의 효율성을 분석

---

## 2. 준비물 및 환경
- Jetson Nano / Orin Nano (JetPack + TensorRT + DeepStream 설치 완료)
- 인터넷 연결 가능 환경 (공개 RTSP 스트림 수신용)
- YOLOv8n 모델 (`ultralytics` 기반)
  - ONNX 변환 및 TensorRT 엔진(`.engine`) 생성 필요

---

## 3. 공개 RTSP 테스트 영상 예시
아래 주소 중 하나를 실험용으로 사용:

| 이름 | RTSP 주소 | 설명 |
|------|------------|------|
| Big Buck Bunny | `rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov` | 가장 안정적인 테스트 스트림 |
| IP Pattern Stream | `rtsp://rtsp.stream/pattern` | 네트워크/디코더 테스트용 패턴 영상 |
| CCTV 데모 | `rtsp://media.smartstream.tv:554/live/ch1` | 간헐적 연결, 실제 도시뷰 영상 |

> 영상 재생이 가능한지 먼저 `gst-launch-1.0`으로 테스트
> ```bash
> gst-launch-1.0 rtspsrc location=rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov latency=0 ! > rtph264depay ! h264parse ! nvv4l2decoder ! nvvidconv ! nveglglessink sync=false
> ```

---

## 4. 디렉토리 구조
```
projC_deepstream_yolo/
├─ models/
│  ├─ yolov8n.onnx
│  ├─ yolov8n_b1_fp16.engine
│  └─ labels.txt
├─ deepstream/
│  ├─ ds_rtsp_yolo.txt
│  └─ nvdsinfer_custom_impl_Yolo/
├─ metrics/
│  ├─ deepstream_perf.csv
│  └─ tegrastats.log
└─ scripts/
   ├─ rtsp_yolo_live.py
   ├─ export_onnx.sh
   ├─ build_engine.sh
   └─ plot_opencv_metrics.py
```

---

## 5. 모델 변환 과정

### 5-1. YOLO → ONNX 변환
```bash
python - <<'PY'
from ultralytics import YOLO
m = YOLO('yolov8n.pt')
m.export(format='onnx', opset=12, imgsz=640)
PY
mv yolov8n.onnx ./models/
```

### 5-2. ONNX → TensorRT 변환
```bash
trtexec   --onnx=./models/yolov8n.onnx   --saveEngine=./models/yolov8n_b1_fp16.engine   --fp16 --memPoolSize=workspace:2048
```

---

## 6. DeepStream 설정 예시 (`deepstream/ds_rtsp_yolo.txt`)
```ini
[application]
enable-perf-measurement=1
perf-measurement-interval-sec=5

[source0]
enable=1
type=4
uri=rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov
num-sources=1
latency=0
drop-frame-interval=0

[streammux]
batch-size=1
width=1280
height=720
live-source=1

[primary-gie]
enable=1
gie-unique-id=1
model-engine-file=../models/yolov8n_b1_fp16.engine
labelfile-path=../models/labels.txt
network-mode=2
parse-bbox-func-name=NvDsInferParseCustomYolo
custom-lib-path=./nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so

[sink0]
enable=1
type=3
sync=0
qos=0
```

---

## 7. 실행 스크립트

### DeepStream 실행
```bash
#!/bin/bash
cd "$(dirname "$0")/../deepstream"
deepstream-app -c ds_rtsp_yolo.txt | tee ../metrics/deepstream_perf.csv
```

자원 사용률 로깅:
```bash
tegrastats --interval 1000 | tee metrics/tegrastats.log
```

---

### YOLO 단독(OpenCV) 실행
```bash
python scripts/rtsp_yolo_live.py   --rtsp rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov   --conf 0.5
```

---

## 8. 측정 및 시각화
- FPS, Latency, GPU/CPU 사용률 측정  
- `deepstream_perf.csv`와 `tegrastats.log`를 Matplotlib으로 시각화  
- YOLO 단독(OpenCV) vs DeepStream 비교 그래프 생성

---

## 9. 과제 체크리스트
1. 공개 RTSP 주소 재생 확인 (`gst-launch-1.0`)  
2. YOLO → ONNX → TensorRT 변환  
3. DeepStream 구성 및 실행  
4. OpenCV + YOLO 단독 실행  
5. FPS / Latency / 자원 사용률 비교  
6. Matplotlib 그래프 작성  
7. 결과 분석 리포트 작성

---

## 10. 문제 해결 팁
- **영상 재생 안 될 때** → 방화벽 또는 RTSP 주소 변경 시도  
- **DeepStream 지연 발생 시** → `latency=0` 옵션 유지  
- **YOLO 입력 크기 오류** → 모델 export 시 `imgsz=640` 일치 확인  
- **FP16 변환 실패 시** → `--fp16` 옵션 제거하고 FP32로 테스트

---

## 11. 최종 산출물
- DeepStream 실행 화면 (탐지 박스 + FPS)
- `deepstream_perf.csv`, `tegrastats.log`
- YOLO(OpenCV) vs DeepStream 성능 비교 그래프
- 성능 분석 및 결과 보고서
