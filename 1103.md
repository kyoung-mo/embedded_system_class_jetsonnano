## 1️⃣ TensorRT 엔진 생성 및 DeepStream 실행 성공  

<img width="1013" height="919" alt="image" src="https://github.com/user-attachments/assets/457d17d8-adbb-489f-942e-ea28172891a3" />

Jetson Orin Nano 환경에서 `deepstream-app` 실행 시  
YOLOv8 ONNX 모델을 기반으로 한 **TensorRT FP16 엔진이 정상적으로 생성되었음**.  

엔진 생성 로그에서  
```
serialize cuda engine to file: /home/kyoungmo/projC_deepstream_yolo/models/yolov8n.onnx_b1_gpu0_fp16.engine successfully
```
가 출력되어 엔진 파일이 `/models` 경로에 성공적으로 저장되었음을 확인함.  

이후 `pgie_yolov8.txt` 에서 해당 경로를 지정하여 재실행한 결과,  
DeepStream 파이프라인이 정상적으로 구동되었으며  
**XLaunch를 통한 원격 GUI 출력도 정상적으로 작동함.**

➡️ 결과적으로 **엔진 생성 및 활성화 절차가 완전히 성공하였으며**,  
이후 동일 환경에서는 추가적인 빌드 없이 엔진 파일을 즉시 로드할 수 있음.

---

## 2️⃣ Docker 환경을 통한 엔진 사전 생성 가능성 검증  

TensorRT 엔진은 모델 구조와 환경(CUDA, TensorRT, JetPack 버전 등)이 동일한 경우  
**도커 환경에서 사전 생성 후 재사용이 가능함**을 확인함.  

- 동일 Jetson 보드, JetPack, TensorRT 버전 간 호환 필요.  
- 컨테이너 내에서 `tensorrt/bin/trtexec` 명령으로 ONNX → Engine 변환 수행 가능.  
- `-v` 옵션으로 호스트 디렉터리(`/models`)를 공유하면  
  컨테이너 내 생성 엔진을 호스트에서도 직접 활용 가능.  
- 이후 DeepStream 실행 시 `pgie_yolov8.txt` 의 `model-engine-file` 항목에 해당 경로 지정.  

➡️ **도커를 활용하면 엔진 생성 시간을 3~10분 단축할 수 있으며**,  
프로젝트 배포 시 동일한 환경에서 엔진 파일을 즉시 활용할 수 있음.

---

## 3️⃣ 연구실–실습실 간 RTSP 스트리밍 구성 가능성 분석  

- 연구실 PC(Windows + 카메라)에서 RTSP 서버 운영.  
- 실습실 Jetson Orin Nano 약 15대가 동시에 접속하는 구조를 검토함.  
- 연구실 공유기 속도: **100 Mbps**, 실습실은 별도 서브넷 사용.  

### 네트워크 연결 및 대역폭 결과  
| 해상도 / 비트레이트 | 1대 수신 트래픽 | 15대 동시 시청 시 총 트래픽 | 평가 |
|--------------------|----------------|-----------------------------|------|
| 720p / 2 Mbps | 2 Mbps | 약 30 Mbps | 안정적 ✅ |
| 1080p / 4 Mbps | 4 Mbps | 약 60 Mbps | 가능 (주의 필요) ⚠️ |
| 1080p / 6 Mbps | 6 Mbps | 약 90 Mbps | 한계 수준 🚨 |
| 1080p / 8 Mbps | 8 Mbps | 약 120 Mbps | 불가능 ❌ |

- **연구실 → 실습실 간 720p~1080p, 3~4 Mbps 수준의 송출이 현실적.**  
- 네트워크 차단 시 포트포워딩(554/8554) 또는 VPN 구성이 필요함.

---

## 4️⃣ 효율적 확장 구조 제안  

### 📁 구조 A — 연구실 1스트림 송출, 실습실 내부 재분배  
- 연구실 PC는 **1개의 RTSP 스트림만 송출**.  
- 실습실 Jetson 중 1대를 **중계 서버(Proxy)** 로 지정하여 조교가 Jetson 1대를 중계기로 이용  
  실습 인원(내부 15대)에게 영상을 재송출.  
- 연구실 ↔ 실습실 구간에는 **1스트림(약 4 Mbps)** 만 흐르며,  
  실습실 내부는 **LAN(1 Gbps급)** 으로 부하가 거의 없음.

```bash
ffmpeg -i rtsp://<연구실IP>:8554/live -f rtsp rtsp://0.0.0.0:8554/relay
```
> 실습실 Jetson: `rtsp://<중계Jetson IP>:8554/relay` 로 수신  

| 구분 | 기존 구조 (직접 송출) | 구조 A (중계 재분배) |
|------|-------------------|----------------------|
| 연구실 송출 스트림 수 | 15개 | **1개** |
| 연구실 ↔ 실습실 대역폭 | 약 60 Mbps 이상 | **약 4 Mbps** |
| 실습실 내부 트래픽 | 거의 없음 | LAN 내부 60 Mbps |
| 공유기 부하 | 높음 | **대폭 감소** |
| 난이도 | 단순 | Jetson 1대 중계 설정 필요 |

➡️ 연구실–실습실 구간의 트래픽을 **15분의 1 수준으로 절감**할 수 있음.

---

## ✅ 5️⃣ 종합 결론  

- **TensorRT 엔진 생성 및 DeepStream 환경 구동에 성공함.**  
- **Docker 환경에서 사전 엔진 빌드 및 재사용이 가능함.**  
- **연구실–실습실 RTSP 다중 접속 구조는 100 Mbps 환경에서도 구현 가능하며,**  
  - 해상도: 720p~1080p  
  - 비트레이트: 3~4 Mbps  
  - 포트포워딩 또는 VPN 구성이 필수임.  
- **구조 A(중계 재분배 방식)** 적용 시 네트워크 부하를 대폭 줄여  
  다수 Jetson 실습 환경에서도 안정적인 실시간 탐지가 가능함.
