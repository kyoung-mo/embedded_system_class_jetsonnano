
## 1️⃣ TensorRT 엔진 생성 및 DeepStream 실행 성공

<img width="1013" height="919" alt="image" src="https://github.com/user-attachments/assets/457d17d8-adbb-489f-942e-ea28172891a3" />

Jetson Orin Nano 환경에서 `deepstream-app` 실행 시  
YOLOv8 ONNX 모델을 기반으로 한 **TensorRT FP16 엔진이 정상적으로 생성되었음**.  
엔진 생성 로그에서  
```
serialize cuda engine to file: /home/kyoungmo/projC_deepstream_yolo/models/yolov8n.onnx_b1_gpu0_fp16.engine successfully
```
가 출력되어, 엔진 파일이 `/models` 경로에 성공적으로 저장되었음을 확인하였음.  

이후 `pgie_yolov8.txt` 에서 해당 경로를 지정하여 재실행한 결과,  
DeepStream 파이프라인이 정상적으로 구동되었으며,  
XLaunch 환경에서 GUI 출력이 가능한 상태로 확인되었음.  

결과적으로 **엔진 생성 및 활성화 절차가 성공적으로 완료되었으며**,  
이후 동일 환경에서는 추가적인 엔진 빌드 과정 없이 바로 로드가 가능한 상태임.

---

## 2️⃣ Docker 환경을 통한 엔진 사전 생성 가능성 확인

TensorRT 엔진은 모델 구조와 연산 환경(CUDA, TensorRT 버전, JetPack 버전 등)이 동일할 경우  
도커 환경에서 **사전 생성 후 재사용이 가능함**을 확인하였음.  

- 동일 Jetson 보드와 JetPack 버전, TensorRT 버전에서만 호환됨.  
- 도커 컨테이너 내에서 `tensorrt/bin/trtexec` 명령으로 ONNX→Engine 변환 수행 가능함.  
- `-v` 옵션으로 호스트 `~/projC_deepstream_yolo/models` 디렉터리를 공유하면  
  컨테이너에서 생성한 엔진을 호스트에서 직접 활용할 수 있음.  
- 이후 DeepStream 실행 시 `pgie_yolov8.txt` 의 `model-engine-file` 경로를 해당 파일로 지정하면 바로 로드됨.  

즉, 도커를 활용하여 엔진을 사전 빌드해두면  
실제 프로젝트 구동 단계에서 엔진 재생성 시간(약 3~10 분)을 절약할 수 있음.

---

## 3️⃣ 연구실–실습실 간 RTSP 스트리밍 구성 가능성 분석

- **연구실 PC(Windows + 카메라)** 에서 RTSP 서버를 운영하고,  
  **실습실 Jetson Orin Nano 15대**가 동시에 접속하는 구조를 검토함.  
- 연구실 공유기 속도는 **100 Mbps** 이며, 실습실과 서브넷(IP 대역)이 상이함.  

### 확인 결과
1. **네트워크 연결성**  
   - 다른 대역 간 연결을 위해 연구실 공유기에서 **RTSP 포트(예: 554 또는 8554) 포워딩** 필요함.  
   - 또는 학교망 내 라우팅/VPN 구성이 되어 있을 경우 직접 접속도 가능함.  

2. **대역폭 및 부하**  
   - 720p(2 Mbps) 기준 → 15대 동시 약 30 Mbps → 안정적 동작 가능함.  
   - 1080p(4 Mbps) 기준 → 약 60 Mbps → 가능하나 공유기 부하 주의 필요함.  
   - 1080p 6 Mbps 이상 → 100 Mbps 한계 초과 가능성이 높음.  

3. **추천 구성**  
   - 연구실 PC → RTSP 720p/3 Mbps 스트림 송출.  
   - 실습실 Jetson 15대 → 직접 접속 또는 중간 프록시 서버를 두어 분산 수신.  
   - 포트포워딩 및 네트워크 테스트 를 통해 외부 접속 확인 필요함.  

결론적으로, **연구실–실습실 간 RTSP 스트리밍은 100 Mbps 환경에서도 가능하나**,  
해상도 및 비트레이트 조정이 필수이며, 연구실 공유기의 포트포워딩 설정 또는 VPN 구성이 필요함.

---

# 📡 연구실–실습실 간 RTSP 스트리밍 구성 검토 보고

---

## 1️⃣ 대역폭 계산 및 가능 범위

연구실 공유기의 업링크 속도가 **100 Mbps**이므로,  
실제 전송 효율을 고려하면 **약 85~90 Mbps** 정도가 안정적으로 사용 가능한 최대 속도임.  

| 해상도 / 비트레이트 | 1대 수신 트래픽 | 15대 동시 접속 시 총 트래픽 | 평가 |
|--------------------|----------------|-----------------------------|------|
| 720p / 2 Mbps | 2 Mbps | 약 30 Mbps | 여유 있음 ✅ |
| 1080p / 4 Mbps | 4 Mbps | 약 60 Mbps | 가능하나 다소 한계 ⚠️ |
| 1080p / 6 Mbps | 6 Mbps | 약 90 Mbps | 거의 한계 🚨 |
| 1080p / 8 Mbps | 8 Mbps | 약 120 Mbps | 100 Mbps 환경에서는 불가능 ❌ |

따라서 현실적인 설정은  
720p~~1080p 해상도, 비트레이트 3~4 Mbps 수준으로 송출하고,  
실습실의 Jetson 15대가 이를 수신하는 형태가 적절함.

---

## 2️⃣ 서로 다른 네트워크(IP 대역) 문제 분석

- 연구실: 예) 192.168.0.x  
- 실습실: 예) 10.10.x.x  

두 네트워크가 서로 다른 공유기·서브넷에 속하므로,  
연구실 PC(스트리밍 서버)에 접근하려면 다음 중 한 가지가 필요함.

1. **포트포워딩 설정**  
   - 연구실 공유기에서 RTSP 포트(기본 554, 또는 사용자 설정 8554)를 개방해야 함.  
   - 실습실에서는 “공유기 공인 IP:포트” 형식으로 접속 가능함.

2. **학교망 라우팅 허용**  
   - 캠퍼스 내부망에서 연구실 대역과 실습실 대역이 라우팅되어 있을 경우 내부 IP로 직접 접속 가능함.

3. **VPN 또는 터널링 구성**  
   - 연구실 PC를 VPN 서버로 설정하고, 실습실 Jetson들이 VPN으로 접속하면  
     동일 네트워크처럼 RTSP 수신이 가능함.  
   - 단, 총 대역폭은 여전히 100 Mbps 내에서 공유됨.

결론적으로,  
**공유기 포트포워딩 또는 캠퍼스 라우팅이 허용되면 RTSP 외부 접속이 가능**하며,  
단일 공유기 환경에서도 실습실 Jetson들이 연구실 PC에 접속할 수 있음.

---

## 3️⃣ 동시 접속 시 발생 가능한 문제점

1. **공유기 성능 한계**  
   - 저가형 100 Mbps 공유기는 세션 수(약 10~15개) 초과 시 버퍼링이나 끊김이 발생할 수 있음.

2. **유니캐스트 방식의 부하**  
   - RTSP가 기본적으로 1대당 1스트림(Unicast) 구조이므로,  
     접속자 수가 증가할수록 송출 대역폭이 선형적으로 증가함.

3. **캠퍼스 네트워크의 QoS 제한**  
   - 학교 네트워크 정책에 따라 연구실 ↔ 실습실 간 트래픽에 속도 제한이 적용될 수 있음.

---

## 4️⃣ 효율적인 구성 방안

### 📁 구조 A: 연구실 → 실습실로 1스트림 송출, 실습실에서 재분배
- 연구실 PC에서 **RTSP 1개 스트림**만 송출.  
- 실습실 Jetson 중 1대를 **중계 서버(프록시)** 로 두고, 나머지 15대에 재송출.  
- 결과적으로 연구실 ↔ 실습실 구간은 1스트림만 통과하므로 대역폭 부담이 최소화됨.

### ⚙️ 구조 B: 비트레이트 조정
- 연구실 RTSP를 **1280×720, 30fps, 2 Mbps**로 송출.  
- Jetson 15대가 모두 접속하더라도 약 30 Mbps 수준으로 유지 가능함.

---

## 5️⃣ 결론

- **연구실 RTSP 서버 → 실습실 Jetson 15대 동시 접속은 기술적으로 가능함.**  
- 단, 공유기 속도(100 Mbps) 한계로 인해 **720p~1080p, 3~4 Mbps 이하 설정이 적절함.**  
- **포트포워딩 또는 VPN 구성**을 통해 네트워크 접근성을 확보해야 하며,  
  실습 환경에서는 우선 **5대 정도로 테스트 후 전체 확장**하는 것이 안정적임.

---
### 📘 종합 결론

- **TensorRT 엔진 생성 및 DeepStream 환경 구동 성공함.**  
- **Docker 환경에서 사전 엔진 생성이 가능하며, 동일 환경에서 재사용 가능함.**  
- **연구실 RTSP 서버 → 실습실 Jetson 15대 동시 접속 구성은 가능하나, 비트레이트 조정 및 네트워크 개방 설정이 필요함.**
