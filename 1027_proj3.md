도커 환경으로 진행 가능한지 확인해보기 - 엔진 관련

# Week 13–14: 프로젝트 C — 공개 RTSP 영상 기반 YOLOv8 vs DeepStream 성능 비교 (중간 진행 보고)

## 1. 진행 목표
Jetson Orin Nano 환경에서 실시간 RTSP 영상 입력을 받아  
1) YOLOv8(Python/OpenCV) 추론 성능 측정  
2) 동일 모델을 DeepStream 파이프라인으로 적용하여 성능 비교 (FPS, Latency, GPU Load)  
을 수행하기 위한 시스템 구성 및 테스트를 진행하였다.

---

## 2. Jetson 개발 환경 구축
| 항목 | 내용 |
|---|---|
| 보드 | Jetson Orin Nano (JetPack 5.1.2 / L4T R35.3.1) |
| CUDA | 11.4 |
| TensorRT | 8.5.2 |
| 개발 방식 | Windows → SSH -Y(Remote X11 Forward) |
| GUI Forward | XLaunch & DISPLAY 설정 완료 (`xclock` 정상 출력) |

→ 원격 환경에서 영상 출력 및 DeepStream 실행 가능 상태 확보.

---

## 3. DeepStream 6.3 설치 (수동 설치)
```bash
sudo tar -xvf deepstream_sdk_v6.3.0_jetson.tbz2 -C /
sudo ldconfig
deepstream-app --version-all
```
✅ DeepStream SDK 6.3 정상 인식

---

## 4. YOLOv8 모델 변환 (PyTorch → ONNX)
```python
from ultralytics import YOLO
m = YOLO("yolov8n.pt")
m.export(format="onnx", opset=12, imgsz=640)
```
| 입력 | 출력 | 모델 크기 | 변환 상태 |
|---|---|---|---|
| images (1×3×640×640) | output0 | ≈ 6.3 MB | ✅ 성공 |

---

## 5. YOLOv8 DeepStream Custom Parser 빌드 ✅
```bash
git clone https://github.com/marcoslucianops/DeepStream-Yolo.git
cd DeepStream-Yolo/nvdsinfer_custom_impl_Yolo
make -j$(nproc)
sudo cp libnvdsinfer_custom_impl_Yolo.so /opt/nvidia/deepstream/deepstream-6.3/lib/
sudo ldconfig
```
→ YOLOv8이 DeepStream 엔진 내에서 정상 처리되도록 파서 적용 완료

---

## 6. RTSP + YOLO(OpenCV) 실시간 테스트 ✅
테스트 스트림:
```
rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov
```
로그 출력 위치:
```
metrics/yolo_opencv_perf.csv
```

| 기능 | 결과 |
|---|---|
| RTSP 영상 수신 | 정상 |
| 실시간 YOLO 추론 | Windows 화면에 X11 포워딩 출력 ✅ |
| FPS 측정 | EMA 기반 실시간 계산 |
| Latency 기록 | 추론 처리시간(ms) 저장 |

→ DeepStream 대비 기준 성능 데이터 확보 완료

---

## 7. DeepStream 구성 상태
- `ds_rtsp_yolo.txt` (메인 파이프라인 설정) 생성 완료
- `pgie_yolov8.txt` (YOLO 엔진 + 파서 설정) 생성 완료
- TensorRT 엔진(`yolov8n_b1_fp16.engine`)은 **DeepStream 실행 시 자동 생성됨**
  → 생성 중 지연 발생은 **정상 동작 과정**

---

## 8. 현재까지 진행 요약
| 항목 | 상태 | 비고 |
|---|---|---|
| YOLOv8 → ONNX 변환 | ✅ 완료 | 모델 구조 정상 |
| DeepStream 6.3 설치 | ✅ 완료 | 실행 확인 |
| YOLOv8 Custom Parser 빌드 | ✅ 완료 | DeepStream 적용 가능 |
| RTSP + YOLO(OpenCV) 실시간 추론 | ✅ 완료 | 성능 로그 생성됨 |
| DeepStream 실행 준비 | ✅ 완료 | 첫 엔진 생성만 남음 |
| TensorRT 엔진 생성 | ⏳ 진행 예정 | 첫 실행 시 자동 생성 |

---

## 9. 다음 단계 (실행 명령)
```bash
cd ~/projC_deepstream_yolo/configs
deepstream-app -c ds_rtsp_yolo.txt
```
※ 첫 실행 시 TensorRT 엔진 생성으로 인해 **1–10분 소요 가능**  
→ 이후 실행은 실시간 즉시 처리 가능

---

## 10. 향후 산출물
- DeepStream 성능 로그 (FPS / Latency / GPU Load)
- YOLO(OpenCV) vs DeepStream 성능 비교 그래프
- 분석 보고서 및 발표 자료

